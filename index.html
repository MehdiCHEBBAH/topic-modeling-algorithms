<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>

<link href='https://fonts.loli.net/css?family=Open+Sans:400italic,700italic,700,400&subset=latin,latin-ext' rel='stylesheet' type='text/css' /><style type='text/css'>
@font-face {
	font-family: 'Computer Modern';
	font-style: normal;
	font-weight: normal;
	src: url('./assets/cmunrm.ttf');
}

@font-face {
	font-family: 'Computer Modern';
	font-style: italic;
	font-weight: normal;
	src: url('./assets/cmunti.ttf');
}

@font-face {
	font-family: 'Computer Modern';
	font-style: normal;
	font-weight: bold;
	src: url('./assets/cmunbx.ttf');
}

@font-face {
	font-family: 'Computer Modern';
	font-style: italic;
	font-weight: bold;
	src: url('./assets/ascmunbi.ttf');
}
html {overflow-x: initial !important;}:root { --bg-color:#ffffff; --text-color:#333333; --select-text-bg-color:#B5D6FC; --select-text-font-color:auto; --monospace:"Lucida Console",Consolas,"Courier",monospace; --title-bar-height:20px; }
.mac-os-11 { --title-bar-height:28px; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
body { margin: 0px; padding: 0px; height: auto; inset: 0px; font-size: 1rem; line-height: 1.42857; overflow-x: hidden; background: inherit; tab-size: 4; }
iframe { margin: auto; }
a.url { word-break: break-all; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { text-shadow: none; background: var(--select-text-bg-color); color: var(--select-text-font-color); }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; overflow-wrap: break-word; position: relative; white-space: normal; overflow-x: visible; padding-top: 36px; }
#write.first-line-indent p { text-indent: 2em; }
#write.first-line-indent li p, #write.first-line-indent p * { text-indent: 0px; }
#write.first-line-indent li { margin-left: 2em; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
.typora-export .footnote-line, .typora-export li, .typora-export p { white-space: pre-wrap; }
.typora-export .task-list-item input { pointer-events: none; }
@media screen and (max-width: 500px) {
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  #write { padding-left: 20px; padding-right: 20px; }
  .CodeMirror-sizer { margin-left: 0px !important; }
  .CodeMirror-gutters { display: none !important; }
}
#write li > figure:last-child { margin-bottom: 0.5rem; }
#write ol, #write ul { position: relative; }
img { max-width: 100%; vertical-align: middle; image-orientation: from-image; }
button, input, select, textarea { color: inherit; font: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
*, ::after, ::before { box-sizing: border-box; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre { width: inherit; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p { position: relative; }
p { line-height: inherit; }
h1, h2, h3, h4, h5, h6 { break-after: avoid-page; break-inside: avoid; orphans: 4; }
p { orphans: 4; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
.md-math-block, .md-rawblock, h1, h2, h3, h4, h5, h6, p { margin-top: 1rem; margin-bottom: 1rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: 700; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.7); color: rgb(85, 85, 85); border-radius: 4px; cursor: pointer; }
sup.md-footnote a, sup.md-footnote a:hover { color: inherit; text-transform: inherit; text-decoration: inherit; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; }
figure { overflow-x: auto; margin: 1.2em 0px; max-width: calc(100% + 16px); padding: 0px; }
figure > table { margin: 0px; }
tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 32px; }
.CodeMirror-gutters { border-right: 0px; background-color: inherit; }
.CodeMirror-linenumber { user-select: none; }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
#write pre { white-space: pre-wrap; }
#write.fences-no-line-wrapping pre { white-space: pre; }
#write pre.ty-contain-cm { white-space: normal; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background: inherit; position: relative !important; }
.md-fences-adv-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
#write .md-fences.mock-cm { white-space: pre-wrap; }
.md-fences.md-fences-with-lineno { padding-left: 0px; }
#write.fences-no-line-wrapping .md-fences.mock-cm { white-space: pre; overflow-x: auto; }
.md-fences.mock-cm.md-fences-with-lineno { padding-left: 8px; }
.CodeMirror-line, twitterwidget { break-inside: avoid; }
.footnotes { opacity: 0.8; font-size: 0.9rem; margin-top: 1em; margin-bottom: 1em; }
.footnotes + .footnotes { margin-top: 0px; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; background: 0px 0px; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; -webkit-tap-highlight-color: transparent; line-height: normal; font-weight: 400; text-align: left; box-sizing: content-box; direction: ltr; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li .mathjax-block, li p { margin: 0.5rem 0px; }
li blockquote { margin: 1rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child, li > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; white-space: normal; }
#write .footnote-line { white-space: pre-wrap; }
@media print {
  body, html { border: 1px solid transparent; height: 99%; break-after: avoid; break-before: avoid; font-variant-ligatures: no-common-ligatures; }
  #write { margin-top: 0px; padding-top: 0px; border-color: transparent !important; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  .typora-export #write { break-after: avoid; }
  .typora-export #write::after { height: 0px; }
  .is-mac table { break-inside: avoid; }
  .typora-export-show-outline .typora-export-sidebar { display: none; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 0.8rem; white-space: pre-wrap; background: rgb(204, 204, 204); display: block; overflow-x: hidden; }
p > .md-image:only-child:not(.md-img-error) img, p > img:only-child { display: block; margin: auto; }
#write.first-line-indent p > .md-image:only-child:not(.md-img-error) img { left: -2em; position: relative; }
p > .md-image:only-child { display: inline-block; width: 100%; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.md-math-block { width: 100%; }
.md-math-block:not(:empty)::after { display: none; }
.MathJax_ref { fill: currentcolor; }
[contenteditable="true"]:active, [contenteditable="true"]:focus, [contenteditable="false"]:active, [contenteditable="false"]:focus { outline: 0px; box-shadow: none; }
.md-task-list-item { position: relative; list-style-type: none; }
.task-list-item.md-task-list-item { padding-left: 0px; }
.md-task-list-item > input { position: absolute; top: 0px; left: 0px; margin-left: -1.2em; margin-top: calc(1em - 10px); border: none; }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc-content::after, .md-toc::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-item a { text-decoration: none; }
.md-toc-inner:hover { text-decoration: underline; }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: 700; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) {
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
code, pre, samp, tt { font-family: var(--monospace); }
kbd { margin: 0px 0.1em; padding: 0.1em 0.6em; font-size: 0.8em; color: rgb(36, 39, 41); background: rgb(255, 255, 255); border: 1px solid rgb(173, 179, 185); border-radius: 3px; box-shadow: rgba(12, 13, 14, 0.2) 0px 1px 0px, rgb(255, 255, 255) 0px 0px 0px 2px inset; white-space: nowrap; vertical-align: middle; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.8; font-family: var(--monospace); }
code { text-align: left; vertical-align: initial; }
a.md-print-anchor { white-space: pre !important; border-width: initial !important; border-style: none !important; border-color: initial !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: 0px !important; background: 0px 0px !important; text-decoration: initial !important; text-shadow: initial !important; }
.os-windows.monocolor-emoji .md-emoji { font-family: "Segoe UI Symbol", sans-serif; }
.md-diagram-panel > svg { max-width: 100%; }
[lang="flow"] svg, [lang="mermaid"] svg { max-width: 100%; height: auto; }
[lang="mermaid"] .node text { font-size: 1rem; }
table tr th { border-bottom: 0px; }
video { max-width: 100%; display: block; margin: 0px auto; }
iframe { max-width: 100%; width: 100%; border: none; }
.highlight td, .highlight tr { border: 0px; }
mark { background: rgb(255, 255, 0); color: rgb(0, 0, 0); }
.md-html-inline .md-plain, .md-html-inline strong, mark .md-inline-math, mark strong { color: inherit; }
.md-expand mark .md-meta { opacity: 0.3 !important; }
mark .md-meta { color: rgb(0, 0, 0); }
@media print {
  .typora-export h1, .typora-export h2, .typora-export h3, .typora-export h4, .typora-export h5, .typora-export h6 { break-inside: avoid; }
}
.md-diagram-panel .messageText { stroke: none !important; }
.md-diagram-panel .start-state { fill: var(--node-fill); }
.md-diagram-panel .edgeLabel rect { opacity: 1 !important; }
.md-fences.md-fences-math { font-size: 1em; }
.md-fences-advanced:not(.md-focus) { padding: 0px; white-space: nowrap; border: 0px; }
.md-fences-advanced:not(.md-focus) { background: inherit; }
.typora-export-show-outline .typora-export-content { max-width: 1440px; margin: auto; display: flex; flex-direction: row; }
.typora-export-sidebar { width: 300px; font-size: 0.8rem; margin-top: 80px; margin-right: 18px; }
.typora-export-show-outline #write { --webkit-flex:2; flex: 2 1 0%; }
.typora-export-sidebar .outline-content { position: fixed; top: 0px; max-height: 100%; overflow: hidden auto; padding-bottom: 30px; padding-top: 60px; width: 300px; }
@media screen and (max-width: 1024px) {
  .typora-export-sidebar, .typora-export-sidebar .outline-content { width: 240px; }
}
@media screen and (max-width: 800px) {
  .typora-export-sidebar { display: none; }
}
.outline-content li, .outline-content ul { margin-left: 0px; margin-right: 0px; padding-left: 0px; padding-right: 0px; list-style: none; }
.outline-content ul { margin-top: 0px; margin-bottom: 0px; }
.outline-content strong { font-weight: 400; }
.outline-expander { width: 1rem; height: 1.42857rem; position: relative; display: table-cell; vertical-align: middle; cursor: pointer; padding-left: 4px; }
.outline-expander::before { content: ""; position: relative; font-family: Ionicons; display: inline-block; font-size: 8px; vertical-align: middle; }
.outline-item { padding-top: 3px; padding-bottom: 3px; cursor: pointer; }
.outline-expander:hover::before { content: ""; }
.outline-h1 > .outline-item { padding-left: 0px; }
.outline-h2 > .outline-item { padding-left: 1em; }
.outline-h3 > .outline-item { padding-left: 2em; }
.outline-h4 > .outline-item { padding-left: 3em; }
.outline-h5 > .outline-item { padding-left: 4em; }
.outline-h6 > .outline-item { padding-left: 5em; }
.outline-label { cursor: pointer; display: table-cell; vertical-align: middle; text-decoration: none; color: inherit; }
.outline-label:hover { text-decoration: underline; }
.outline-item:hover { border-color: rgb(245, 245, 245); background-color: var(--item-hover-bg-color); }
.outline-item:hover { margin-left: -28px; margin-right: -28px; border-left: 28px solid transparent; border-right: 28px solid transparent; }
.outline-item-single .outline-expander::before, .outline-item-single .outline-expander:hover::before { display: none; }
.outline-item-open > .outline-item > .outline-expander::before { content: ""; }
.outline-children { display: none; }
.info-panel-tab-wrapper { display: none; }
.outline-item-open > .outline-children { display: block; }
.typora-export .outline-item { padding-top: 1px; padding-bottom: 1px; }
.typora-export .outline-item:hover { margin-right: -8px; border-right: 8px solid transparent; }
.typora-export .outline-expander::before { content: "+"; font-family: inherit; top: -1px; }
.typora-export .outline-expander:hover::before, .typora-export .outline-item-open > .outline-item > .outline-expander::before { content: "−"; }
.typora-export-collapse-outline .outline-children { display: none; }
.typora-export-collapse-outline .outline-item-open > .outline-children, .typora-export-no-collapse-outline .outline-children { display: block; }
.typora-export-no-collapse-outline .outline-expander::before { content: "" !important; }
.typora-export-show-outline .outline-item-active > .outline-item .outline-label { font-weight: 700; }
.md-inline-math-container mjx-container { zoom: 0.95; }


:root {
	--primary-color: #2875d9;
}

* {
	box-sizing: border-box;
}

html, body, #write {
	font-family: 'Computer Modern';
}

h1, h2, h3, h4, h5, h6 {
	font-family: 'Computer Modern';
}

h1 {
	font-size: 2rem;
}

h2 {
	font-size: 1.8rem;
}

h3 {
	font-size: 1.6rem;
}

h4 {
	font-size: 1.4rem;
}

h5 {
	font-size: 1.2rem;
}

h6 {
	font-size: 1rem;
}

html {
	font-size: 20px;
}

body, #write {
	max-width: 914px;
	text-align: justify;
	display: block;
	margin: auto;
}

p {
	font-size: 1rem;
}

a {
	color: var(--primary-color);
}

/* Stuff */

sup.md-footnote {
	background-color: transparent;
	color: var(--primary-color);
	padding: 1px;
	margin: 0;
}

code, .md-fences, .sourceCode {
	background: #f2f2f2;
}

.md-fences, pre.sourceCode {
	font-size: .7em;
	padding: .5rem;
}

.show-fences-line-number .md-fences {
	padding-left: .5rem;
}

blockquote {
	margin: 2rem .2rem;
	padding: .3rem .5rem;
	color: #6f6f6f;
	border-left: .4rem solid gray;
}

blockquote p {
	padding: .2rem 1.5rem;
}

mark {
	background: yellow;
}

figure {
	margin: .5rem auto;
	max-width: 100%;
	display: block;
	margin: auto;
}

figcaption {
	text-align: center;
	margin: .5rem auto;
}

img {
	max-width: 100%;
	display: block;
	margin: auto;
}

/* Styling tables */ 
table {
    border-collapse: collapse;
    margin: 5px 0;
    box-shadow: 0 0 20px rgba(0, 0, 0, 0.15);
}

table thead tr {
    background-color: #009879;
    color: #ffffff;
    text-align: left;
}

table th,
table td {
    padding: 12px 15px;
}

table tbody tr {
    border-bottom: thin solid #dddddd;
}

table tbody tr:nth-of-type(even) {
    background-color: #f3f3f3;
}

table tbody tr:last-of-type {
    border-bottom: 2px solid #009879;
}

table tbody tr.md-focus-container {
    font-weight: bold;
    color: #009879;
}
/* 
    Print Mode and page breaks.
    WkhtmlToPDF does not work on @print mode
*/

@media (max-width: 210mm) {
	img {
		max-height: 8cm;
	}
	html {
		font-size: 16px;
	}
	div[title="pb"], page-break {
		display: block;
		page-break-after: always;
		break-after: page;
	}
	nav {
		font-size: .9rem;
		page-break-after: always;
		page-break-before: always;
	}
	nav a {
		color: black;
	}
	/* Move top-level headings to a new page on the right-hand side: */
	h1, h2 {
		page-break-before: right;
		break-before: recto;
	}
	/* Override the previous ruleset for the very first heading: */
	h1:first-of-type, section>h1:first-child {
		page-break-before: avoid;
		break-before: avoid;
	}
	/* Headings should not be the last paragraph on a page: */
	h1, h2, h3, h4, h5, h6 {
		page-break-after: avoid;
	}
	/* Consecutive headings with deepening level should not be split across pages: */
	h1+h2, h2+h3, h3+h4, h4+h5, h5+h6 {
		page-break-before: avoid;
	}
}

/* completely hide the element where it is not needed */
.page-break
{
    display: none; 
}
@media print, (overflow-block: paged) or (overflow-block: optional-paged)
{
  .page-break
  {
    display: block;
    page-break-after: always; /* CSS 2 */
         break-after: page;   /* CSS 3+ */
  }
}

p
{
	text-align: justify;
}


mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}
mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
							stroke-width: 0;
						}
</style><title>LDA, NMF, Top2Vec, and BERTopic. How do they work?
</title>

<meta name="description" content="In this article, we will go through the literature on Topic Modeling. We will present an overview of the most interesting techniques, explain how they work, and extract their characteristics that play an important role when choosing the right model for your problem.">
<meta name="robots" content="index, follow">
<meta property="og:type" content="article" />
<meta property="og:title" content="LDA, NMF, Top2Vec, and BERTopic. How do they work?" />
<meta property="og:description" content="In this article, we will go through the literature on Topic Modeling. We will present an overview of the most interesting techniques, explain how they work, and extract their characteristics that play an important role when choosing the right model for your problem." />
<meta property="og:site_name" content="Mehdi CHEBBAH | Blog" />

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
</script>
    
<script type="text/javascript"
        src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

</head>
<body class='typora-export'><div class='typora-export-content'>
<div id='write'  class=''><div style="text-align:center;font-size:30px">﷽</div><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><div style="text-align:center;font-size:48px">LDA, NMF, Top2Vec, and BERTopic. How do they work?</div><p>&nbsp;</p><p>&nbsp;</p><p><span>Written by </span><strong><span>CHEBBAH Mehdi</span></strong></p><hr /><p><img src="./assets/Cover.jpg" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h1 id='introduction'><span>Introduction</span></h1><p><em><span>Topic modeling</span></em><span> (or </span><em><span>topic extraction</span></em><span>) is a technique in Natural Language Processing (NLP) that allows the machine to extract meaning from text by identifying recurrent abstract themes or topics represented by the most relevant keywords.</span></p><p><span>In this article, we will go through the literature on Topic Modeling. We will present an overview of the most interesting techniques, explain how they work, and extract their characteristics that play an important role when choosing the right model for your problem.</span></p><h2 id='lda'><span>LDA</span></h2><p><strong><span>LDA</span></strong><span> or </span><strong><span>Latent Dirichlet Allocation</span></strong><span> is a probabilistic model proposed by </span><em><span>Pritchard</span></em><span>, </span><em><span>Stephens</span></em><span>, and </span><em><span>Donnelly</span></em><span> in 2000. Then it was applied in machine learning by </span><em><span>Blei David</span></em><span>, </span><em><span>Ng Andrew</span></em><span>, and </span><em><span>Jordan Michael</span></em><span> in 2003. </span></p><p><span>Technically, a document in </span><strong><span>LDA</span></strong><span> is a probability distribution of topics and a topic in its turn is a probability distribution of words, so in the training phase, </span><strong><span>LDA</span></strong><span> model tries to find -in the same time- the best distribution of topics in each Document, and the best distribution of words in each topic that describe better the dataset. And this is how it does that:</span></p><p><img src="assets/LDA.png"  /></p><ul><li><span>The model takes two inputs: </span><strong><span>The Document-Term Matrix</span></strong><span> (The order of words is ignored in LDA so the input is </span><strong><span>BOW: Bag Of Words</span></strong><span>) and </span><strong><span>the Number of Topics $K$</span></strong><span> this number is hard to detect beforehand, so this hyper-parameter have to be fine-tuned.</span></li></ul><ol start='2' ><li><p><span>Assign each word in each document to a random topic which will give a </span><strong><span>Bad</span></strong><span> distribution of topics over documents and a </span><strong><span>Bad</span></strong><span> distribution of words over topics.</span></p></li><li><p><span>For each document $d_i$ and for each Word $w_j$, calculate $P(w_j | t_k)$ and $P(t_k|d_i)$ for each topic $t_{k=1,2,..,K}$.</span></p><p><strong><span>Note</span></strong><span>: In some implementations of LDA, two density factors are introduced in the calculation of these probabilities: a document-topic density factor $\alpha$ and a topic-word density factor $\beta$ which are two other hyper-parameters for the model.</span></p></li><li><p><span>Re-assign each word to a topic where  $P(w_j | t_k) \times P(t_k|d_i)$ is maximum.</span></p></li><li><p><span>Repeat steps 3 and 4 until the model converges or to a pre-defined number of iterations.</span></p></li></ol><ul><li><span>The output of the model is the distribution of the topics over documents and the distribution of words over topics</span></li></ul><h3 id='properties-1'><span>Properties</span></h3><ul><li><span>Consider a document as a mixture of topics.</span></li><li><span>Works better with long texts.</span></li><li><span>A non-deterministic approach.</span></li><li><span>Language agnostic.</span></li></ul><h3 id='nmf'><span>NMF</span></h3><p><strong><span>NMF</span></strong><span> or </span><strong><span>Non-negative Matrix Factorization</span></strong><span> is a Linear-algebraic model. The basic idea behind it is to try to factories the input $A$ -which is the words-documents matrix- to get two other matrices (words-topics matrix $W$ and topics-documents matrix $H$) where $A = W \times H$. The algorithm for calculating these matrices is described below:</span></p><p><img src="assets/NMF.png" referrerpolicy="no-referrer" alt="NMF pic"></p><ul><li><span>The input for this model is the words-documents matrix $A$ of dimension $(n\times m)$ and the number of topics $K$.</span></li></ul><ol start='' ><li><span>Randomly initialize the two matrices $W$ of dimension $(n \times K)$ and $H$ of dimension $(K \times m)$.</span></li><li><span>Reconstruct the matrix $\hat{A} = W \times H$.</span></li><li><span>Calculate the distance between $A$ and $\hat{A}$ (euclidean distance).</span></li><li><span>Update values in $W$ and $H$ based on an objective function.</span></li><li><span>Repeat steps 2, 3, and 4 until convergence.</span></li></ol><ul><li><span>The output of the model is $W$ and $H$ matrices.</span></li></ul><h3 id='properties-2'><span>Properties</span></h3><ul><li><span>Calculates how well each document fits each topic.</span></li><li><span>Usually faster than LDA.</span></li><li><span>Works better with brief texts.</span></li><li><span>A deterministic approach.</span></li><li><span>Language agnostic.</span></li></ul><h3 id='top2vec'><span>Top2Vec</span></h3><p><strong><span>Top2Vec</span></strong><span> is an algorithm for topic modeling and semantic search. It automatically detects topics present in text and generates jointly embedded topic, document and word vectors. </span><strong><span>Top2Vec</span></strong><span> was first published in arXiv by </span><em><span>Dimo Angelov</span></em><span> in 2020. It works as follows:</span></p><p><img src="assets/Top2Vec.png" referrerpolicy="no-referrer"></p><ul><li><span>The model takes the collection of documents only as an input.</span></li></ul><ol start='' ><li><span>Embed the inputs using an Embedding model (There are three options for accomplishing this task: </span><strong><span>Universal Sentence Encoder (USE)</span></strong><span>, </span><strong><span>Sentence BERT (SBERT)</span></strong><span>, and </span><strong><span>Document to Vector (Doc2Vec)</span></strong><span>.</span></li><li><span>Reduce the dimensionality of the Embeddings space using the </span><strong><span>UMAP</span></strong><span> algorithm to create dense areas. These dense areas contain geometrically close words (Semantically close Words).</span></li><li><span>Cluster the results using a density-based clustering algorithm (The </span><strong><span>HDBSCAN</span></strong><span> is used here). Then calculate the centroids of each cluster (These centroids are considered as the representative vector of the topic).</span></li><li><span>Get the $K$ closest words to the center of each cluster using the </span><strong><span>K-NN</span></strong><span> algorithm (These words represent the keywords of each topic). </span></li></ol><ul><li><span>The outputs of this model are the list of topics and keywords and the trained model that could be used later to cluster new documents into the right topic.</span></li></ul><h3 id='properties-3'><span>Properties</span></h3><ul><li><span>Training is slow.</span></li><li><span>Automatically finds the number of topics.</span></li><li><span>Works on brief text.</span></li><li><span>Language agnostic if used with doc2vec embedding technique.</span></li><li><span>A non-deterministic approach.</span></li><li><span>Bad with few number of documents.</span></li></ul><h3 id='bertopic'><span>BERTopic</span></h3><p><strong><span>BERTopic</span></strong><span> is a topic modeling technique that leverages transformers and c-TF-IDF to create dense clusters allowing for easily interpretable topics whilst keeping important words in the topic descriptions. </span><strong><span>BERTopic</span></strong><span> is the newest topic modeling technique in the list, it was published in 2020 by </span><em><span>Maarten Grootendorst</span></em><span>. Here how it works:</span></p><p><img src="assets/BERTopic.png" referrerpolicy="no-referrer"></p><ul><li><span>It only takes one input, which is the collection of documents.</span></li></ul><ol start='' ><li><p><span>Embed documents using a BERT-based embedding model (Choose the right Transformers-based pre-trained model for your language as this approach doesn’t contain a training neither a fine-tuning phase for the embedding model)</span></p></li><li><p><span>Cluster documents by reducing the dimensionality </span></p><ol start='' ><li><span>Lower the dimensionality of the Embeddings using the </span><strong><span>UMAP</span></strong><span> algorithm.</span></li><li><span>Create clusters using a density-based algorithm such </span><strong><span>HDBSCAN</span></strong><span>.</span></li></ol></li><li><p><span>Create topics from these clusters, by:</span></p><ol start='' ><li><span>Apply a modified version of TF-IDF called class-based TF-IDF (c-TF-IDF) . This version relies on the idea that instead of calculating the importance of words in documents (which is done by TF-IDF) we calculate the importance of words in clusters. Which will allow us to get the most important words in each topic (Representative words).</span></li><li><span>Improve the coherence of words in each topic, using the </span><strong><span>Maximal Marginal Relevance (MMR)</span></strong><span> to find the most coherent words without having too much overlap between the words themselves. This results in the removal of words that do not contribute to a topic.</span></li></ol></li></ol><ul><li><span>The results are the list of topics and top keywords in each topic besides the model that could be used later for extracting topics from new documents.</span></li></ul><h3 id='properties-4'><span>Properties</span></h3><ul><li><span>Training is slow.</span></li><li><span>Automatically finds the number of topics.</span></li><li><span>Works on brief text.</span></li><li><span>A non-deterministic approach.</span></li><li><span>Language agnostic (Any Transformers-based embedding model could be used for embedding phase).</span></li><li><span>Bad with few number of documents.</span></li></ul><p>&nbsp;</p><h1 id='conclusion'><span>Conclusion</span></h1><p><span>These were 4 methods for topic modeling: </span></p><ul><li><span>A probabilistic model: LDA</span></li><li><span>An algebric model: NMF</span></li><li><span>A hybrid approach: Top2Vec, BERTopic</span></li></ul><p><span>If you are intersted in other articles like this, visit me on:</span></p><ul><li><span>My website: </span><a href='https://mehdi-chebbah.ml/' target='_blank' class='url'>https://mehdi-chebbah.ml/</a></li><li><span>my Blog: </span><a href='http://mehdi-chebbah.ml/blog/' target='_blank' class='url'>http://mehdi-chebbah.ml/blog/</a></li><li><span>Medium: </span><a href='https://medium.com/@mehdi_chebbah' target='_blank' class='url'>https://medium.com/@mehdi_chebbah</a></li><li><span>LinkedIn: </span><a href='https://www.linkedin.com/in/mehdi-chebbah/' target='_blank' class='url'>https://www.linkedin.com/in/mehdi-chebbah/</a></li><li><span>Twitter: </span><a href='https://twitter.com/MehdiCHEBBAH1' target='_blank' class='url'>https://twitter.com/MehdiCHEBBAH1</a></li></ul><h1 id='references'><span>References</span></h1><ul><li><a href='http://genetics.org/content/155/2/945' target='_blank' class='url'>http://genetics.org/content/155/2/945</a></li><li><a href='https://jmlr.csail.mit.edu/papers/v3/blei03a.html' target='_blank' class='url'>https://jmlr.csail.mit.edu/papers/v3/blei03a.html</a></li><li><a href='https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation#cite_note-blei2003-3' target='_blank' class='url'>https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation#cite_note-blei2003-3</a></li><li><a href='https://medium.com/ml2vec/topic-modeling-is-an-unsupervised-learning-approach-to-clustering-documents-to-discover-topics-fdfbf30e27df' target='_blank' class='url'>https://medium.com/ml2vec/topic-modeling-is-an-unsupervised-learning-approach-to-clustering-documents-to-discover-topics-fdfbf30e27df</a></li><li><a href='https://www.researchgate.net/figure/Conceptual-illustration-of-non-negative-matrix-factorization-NMF-decomposition-of-a_fig1_312157184' target='_blank' class='url'>https://www.researchgate.net/figure/Conceptual-illustration-of-non-negative-matrix-factorization-NMF-decomposition-of-a_fig1_312157184</a></li><li><a href='https://github.com/MaartenGr/BERTopic' target='_blank' class='url'>https://github.com/MaartenGr/BERTopic</a></li><li><a href='https://doi.org/10.5281/zenodo.4381785' target='_blank' class='url'>https://doi.org/10.5281/zenodo.4381785</a></li><li><a href='https://top2vec.readthedocs.io/en/latest/Top2Vec.html' target='_blank' class='url'>https://top2vec.readthedocs.io/en/latest/Top2Vec.html</a></li><li><a href='https://arxiv.org/abs/2008.09470' target='_blank' class='url'>https://arxiv.org/abs/2008.09470</a></li></ul></div></div>
<div id="disqus_thread"></div>
<script>
    /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
    
    var disqus_config = function () {
    this.page.url = "http://mehdi-chebbah.ml/topic-modeling-algorithms/";  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = "topic-modeling-algorithms"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://mehdi-chebbah.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
      
  </body>
</html>